{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import gzip\n",
    "import wget\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "import time\n",
    "import nltk\n",
    "from imp import reload\n",
    "\n",
    "#cleaning textfiles libraries\n",
    "from collections import defaultdict # For accumlating values\n",
    "from nltk.corpus import stopwords # To remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##download data from url\n",
    "### randomly selected file to model\n",
    "url = 'https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Grocery_and_Gourmet_Food_5.json.gz'\n",
    "#filename = wget.download(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load metadata\n",
    "data = []\n",
    "with gzip.open('Grocery_and_Gourmet_Food_5.json.gz') as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()))\n",
    "    \n",
    "# total length of list, this number equals total number of products\n",
    "print(len(data))\n",
    "\n",
    "# first row of the list\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list into pandas dataframe\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at dataframe\n",
    "df.info()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that don't impact\n",
    "df = df.drop(['style','summary','image'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert vote column to float\n",
    "\n",
    "df['vote']=df['vote'].str.replace(',','')\n",
    "df[\"vote\"]= df[\"vote\"].fillna(0)\n",
    "df[\"vote\"] = df[\"vote\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert column to string\n",
    "df[\"reviewText\"]=df[\"reviewText\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inserting helpful flag to be used in EDA and Models\n",
    "df['helpful_flag'] = np.where(df['vote'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine Average Review Length and add review length column to dataframe\n",
    "\n",
    "x = [len(df['reviewText'][i]) for i in range(df['reviewText'].shape[0])]\n",
    "print('average length of review: {:.3f}'.format(sum(x)/len(x)) )\n",
    "\n",
    "df['totalWords'] = df['reviewText'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create initial data set for first test \n",
    "df_initial = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we looked to remove duplicates with the same review time and review IDs as they were assummed to be computer generated and not human generated \n",
    "\n",
    "\n",
    "duplicated_reviews = df.duplicated(subset=[\"reviewerID\",\"reviewTime\",\"reviewText\"], keep='first') #returns a Series with True and False values that describe which rows in the DataFrame are duplicated and not.\n",
    "count_duplicated_reviews = duplicated_reviews.value_counts()\n",
    "\n",
    "sum_reviews = count_duplicated_reviews.sum()\n",
    "perc_duplicated_reviews = (count_duplicated_reviews/sum_reviews) * 100\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"\",\"Count\",\"Percentage of Total\"]\n",
    "x.add_rows([\n",
    "    [\"Duplicate Reviews\", count_duplicated_reviews[True], perc_duplicated_reviews[True]],\n",
    "    [\"Original Reviews\", count_duplicated_reviews[False], perc_duplicated_reviews[False]],\n",
    "])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicates = df[duplicated_reviews]\n",
    "df_duplicates.sort_values(by = ['totalWords'], ascending = [False])\n",
    "df_duplicates[df_duplicates['vote'] == 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[(df['reviewerID'] == 'A2N8B21NWXHIW7') & (df['unixReviewTime'] == 1469145600) ]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate reviews for df\n",
    "df = df[~duplicated_reviews]\n",
    "\n",
    "print(f\"Number of reviews after removel of duplicates : {df.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abccc23d8b745288606dc03cd34dd9af4292ead0b0f04e93e928d4f842db1170"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

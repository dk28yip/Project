{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4073d00f",
   "metadata": {},
   "source": [
    "# User reviews classifier to predict of a product review will be useful for other users. (Data set Amazon)\n",
    "\n",
    "\n",
    "**Use Case**: As user prepares and submits a review, how can companies proactively identify reviews not to be posted towards an item that as not a helpful for other users?\n",
    "\n",
    "**Target Variable** Helpful response from other reviewers (this is a target variable that is constructed by a rating on actual reviews done by other users using the scale from vote or helpful)\n",
    "\n",
    "**Data Source** https://nijianmo.github.io/amazon/index.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "631b36ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 998 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import gzip\n",
    "import wget\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "import time\n",
    "import nltk\n",
    "from imp import reload\n",
    "\n",
    "#cleaning textfiles libraries\n",
    "from collections import defaultdict # For accumlating values\n",
    "from nltk.corpus import stopwords # To remove stopwords\n",
    "from gensim import corpora # To create corpus and dictionary for the LDA model\n",
    "from gensim.models import LdaModel # To use the LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e0520",
   "metadata": {},
   "source": [
    "# tested links\n",
    "- http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Arts_Crafts_and_Sewing_5.json.gz - works\n",
    "- http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Grocery_and_Gourmet_Food_5.json.gz - works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d33f6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "##download data from url\n",
    "### randomly selected file to model\n",
    "url = 'https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Grocery_and_Gourmet_Food_5.json.gz'\n",
    "#filename = wget.download(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "927aced5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143860\n",
      "{'overall': 5.0, 'verified': True, 'reviewTime': '11 19, 2014', 'reviewerID': 'A1QVBUH9E1V6I8', 'asin': '4639725183', 'reviewerName': 'Jamshed Mathur', 'reviewText': 'No adverse comment.', 'summary': 'Five Stars', 'unixReviewTime': 1416355200}\n"
     ]
    }
   ],
   "source": [
    "#load metadata\n",
    "data = []\n",
    "with gzip.open('Grocery_and_Gourmet_Food_5.json.gz') as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()))\n",
    "    \n",
    "# total length of list, this number equals total number of products\n",
    "print(len(data))\n",
    "\n",
    "# first row of the list\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5f31ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143860\n"
     ]
    }
   ],
   "source": [
    "# convert list into pandas dataframe\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "print(len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f9015e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1143860 entries, 0 to 1143859\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   overall         1143860 non-null  float64\n",
      " 1   verified        1143860 non-null  bool   \n",
      " 2   reviewTime      1143860 non-null  object \n",
      " 3   reviewerID      1143860 non-null  object \n",
      " 4   asin            1143860 non-null  object \n",
      " 5   reviewerName    1143722 non-null  object \n",
      " 6   reviewText      1143470 non-null  object \n",
      " 7   summary         1143641 non-null  object \n",
      " 8   unixReviewTime  1143860 non-null  int64  \n",
      " 9   vote            158202 non-null   object \n",
      " 10  style           592086 non-null   object \n",
      " 11  image           9510 non-null     object \n",
      "dtypes: bool(1), float64(1), int64(1), object(9)\n",
      "memory usage: 97.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>11 19, 2014</td>\n",
       "      <td>A1QVBUH9E1V6I8</td>\n",
       "      <td>4639725183</td>\n",
       "      <td>Jamshed Mathur</td>\n",
       "      <td>No adverse comment.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1416355200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10 13, 2016</td>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>4639725183</td>\n",
       "      <td>itsjustme</td>\n",
       "      <td>Gift for college student.</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>1476316800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>11 21, 2015</td>\n",
       "      <td>A32RD6L701BIGP</td>\n",
       "      <td>4639725183</td>\n",
       "      <td>Krystal Clifton</td>\n",
       "      <td>If you like strong tea, this is for you. It mi...</td>\n",
       "      <td>Strong</td>\n",
       "      <td>1448064000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>08 12, 2015</td>\n",
       "      <td>A2UY1O1FBGKIE6</td>\n",
       "      <td>4639725183</td>\n",
       "      <td>U. Kane</td>\n",
       "      <td>Love the tea. The flavor is way better than th...</td>\n",
       "      <td>Great tea</td>\n",
       "      <td>1439337600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>05 28, 2015</td>\n",
       "      <td>A3QHVBQYDV7Z6U</td>\n",
       "      <td>4639725183</td>\n",
       "      <td>The Nana</td>\n",
       "      <td>I have searched everywhere until I browsed Ama...</td>\n",
       "      <td>This is the tea I remembered!</td>\n",
       "      <td>1432771200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143855</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 8, 2017</td>\n",
       "      <td>A223YRQH2Z5T1D</td>\n",
       "      <td>B01HJF6FRA</td>\n",
       "      <td>flint5292</td>\n",
       "      <td>As a new vegan, it is sometimes difficult to r...</td>\n",
       "      <td>As a new vegan, it is sometimes difficult to ...</td>\n",
       "      <td>1504828800</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143856</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>08 4, 2017</td>\n",
       "      <td>A38GDA4TB9EILT</td>\n",
       "      <td>B01HJF6FRA</td>\n",
       "      <td>Moriah Bolyard</td>\n",
       "      <td>The best thing ever is ordering a product you ...</td>\n",
       "      <td>The best thing ever is ordering a product you ...</td>\n",
       "      <td>1501804800</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143857</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 4, 2017</td>\n",
       "      <td>A2025PN7HDC5BO</td>\n",
       "      <td>B01HJF6FRA</td>\n",
       "      <td>M.C</td>\n",
       "      <td>I used to love ranch before I became vegan. It...</td>\n",
       "      <td>Just what the vegan ordered!</td>\n",
       "      <td>1499126400</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143858</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>06 7, 2017</td>\n",
       "      <td>A1NY7XWC7EPQOA</td>\n",
       "      <td>B01HJF6FRA</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>I cannot have dairy nor gluten.  This is as cl...</td>\n",
       "      <td>This is as close to Ranch as I will ever be ab...</td>\n",
       "      <td>1496793600</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143859</th>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>05 20, 2017</td>\n",
       "      <td>A1P0X9E6F99J4T</td>\n",
       "      <td>B01HJF6FRA</td>\n",
       "      <td>Qoyllor</td>\n",
       "      <td>Needs improvement to make it taste like real r...</td>\n",
       "      <td>So so</td>\n",
       "      <td>1495238400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1143860 rows Ã 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0            5.0      True  11 19, 2014  A1QVBUH9E1V6I8  4639725183   \n",
       "1            5.0      True  10 13, 2016  A3GEOILWLK86XM  4639725183   \n",
       "2            5.0      True  11 21, 2015  A32RD6L701BIGP  4639725183   \n",
       "3            5.0      True  08 12, 2015  A2UY1O1FBGKIE6  4639725183   \n",
       "4            5.0      True  05 28, 2015  A3QHVBQYDV7Z6U  4639725183   \n",
       "...          ...       ...          ...             ...         ...   \n",
       "1143855      5.0      True   09 8, 2017  A223YRQH2Z5T1D  B01HJF6FRA   \n",
       "1143856      5.0      True   08 4, 2017  A38GDA4TB9EILT  B01HJF6FRA   \n",
       "1143857      5.0      True   07 4, 2017  A2025PN7HDC5BO  B01HJF6FRA   \n",
       "1143858      5.0      True   06 7, 2017  A1NY7XWC7EPQOA  B01HJF6FRA   \n",
       "1143859      3.0      True  05 20, 2017  A1P0X9E6F99J4T  B01HJF6FRA   \n",
       "\n",
       "            reviewerName                                         reviewText  \\\n",
       "0         Jamshed Mathur                                No adverse comment.   \n",
       "1              itsjustme                          Gift for college student.   \n",
       "2        Krystal Clifton  If you like strong tea, this is for you. It mi...   \n",
       "3                U. Kane  Love the tea. The flavor is way better than th...   \n",
       "4               The Nana  I have searched everywhere until I browsed Ama...   \n",
       "...                  ...                                                ...   \n",
       "1143855        flint5292  As a new vegan, it is sometimes difficult to r...   \n",
       "1143856   Moriah Bolyard  The best thing ever is ordering a product you ...   \n",
       "1143857              M.C  I used to love ranch before I became vegan. It...   \n",
       "1143858       Greensboro  I cannot have dairy nor gluten.  This is as cl...   \n",
       "1143859          Qoyllor  Needs improvement to make it taste like real r...   \n",
       "\n",
       "                                                   summary  unixReviewTime  \\\n",
       "0                                               Five Stars      1416355200   \n",
       "1                                           Great product.      1476316800   \n",
       "2                                                   Strong      1448064000   \n",
       "3                                                Great tea      1439337600   \n",
       "4                            This is the tea I remembered!      1432771200   \n",
       "...                                                    ...             ...   \n",
       "1143855   As a new vegan, it is sometimes difficult to ...      1504828800   \n",
       "1143856  The best thing ever is ordering a product you ...      1501804800   \n",
       "1143857                       Just what the vegan ordered!      1499126400   \n",
       "1143858  This is as close to Ranch as I will ever be ab...      1496793600   \n",
       "1143859                                              So so      1495238400   \n",
       "\n",
       "        vote style image  \n",
       "0        NaN   NaN   NaN  \n",
       "1        NaN   NaN   NaN  \n",
       "2        NaN   NaN   NaN  \n",
       "3        NaN   NaN   NaN  \n",
       "4        NaN   NaN   NaN  \n",
       "...      ...   ...   ...  \n",
       "1143855    4   NaN   NaN  \n",
       "1143856    3   NaN   NaN  \n",
       "1143857    5   NaN   NaN  \n",
       "1143858    2   NaN   NaN  \n",
       "1143859  NaN   NaN   NaN  \n",
       "\n",
       "[1143860 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#look at dataframe\n",
    "df.info()\n",
    "display(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76b9a0",
   "metadata": {},
   "source": [
    "### Data catalogue\n",
    "\n",
    "- __overall:__- Rating of the Product\n",
    "- __reviewTime:__- Time of the review (raw)\n",
    "- __reviewerID:__- ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "- __asin:__- ID of the product, e.g. 0000013714\n",
    "- __style:__- A dictionary of the product metadata, e.g., \"Format\" is \"Hardcover\"\n",
    "- __reviewerName:__- Name of the reviewer\n",
    "- __reviewerText:__- Text of the review\n",
    "- __summary:__- Summary of the review\n",
    "- __vote:__- Helpful votes of the review\n",
    "- __unixReviewTime:__- Time of the review (unix time)\n",
    "- __reviewText:__- Text of the review\n",
    "- __image:__- Images that users post after they have received the product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c17745e",
   "metadata": {},
   "source": [
    "### Initital Data clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ef86a",
   "metadata": {},
   "source": [
    "#### a) Check for NAs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "131a42b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Triston\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\plotly\\io\\_renderers.py:395: DeprecationWarning:\n",
      "\n",
      "distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\n",
      "C:\\Users\\Triston\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\plotly\\io\\_renderers.py:395: DeprecationWarning:\n",
      "\n",
      "distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Type=Missingness<br>Feature=%{x}<br>Missing %=%{y}<extra></extra>",
         "legendgroup": "Missingness",
         "marker": {
          "color": "red",
          "opacity": 0.6,
          "pattern": {
           "shape": ""
          }
         },
         "name": "Missingness",
         "offsetgroup": "Missingness",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "overall",
          "verified",
          "reviewTime",
          "reviewerID",
          "asin",
          "unixReviewTime",
          "reviewerName",
          "summary",
          "reviewText",
          "style",
          "vote",
          "image"
         ],
         "xaxis": "x",
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0.0121,
          0.0191,
          0.0341,
          48.2379,
          86.1695,
          99.1686
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Type=Completeness<br>Feature=%{x}<br>Missing %=%{y}<extra></extra>",
         "legendgroup": "Completeness",
         "marker": {
          "color": "#808080",
          "opacity": 0.6,
          "pattern": {
           "shape": ""
          }
         },
         "name": "Completeness",
         "offsetgroup": "Completeness",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "overall",
          "verified",
          "reviewTime",
          "reviewerID",
          "asin",
          "reviewerName",
          "reviewText",
          "summary",
          "unixReviewTime",
          "vote",
          "style",
          "image"
         ],
         "xaxis": "x",
         "y": [
          100,
          100,
          100,
          100,
          100,
          99,
          99,
          99,
          100,
          13,
          51,
          0
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 800,
        "legend": {
         "title": {
          "text": "Type"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Missingness Plot (N=1143860)"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Feature"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Missing %"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Any missing values in the dataset\n",
    "def plot_missingness(df: pd.DataFrame=df) -> None:\n",
    "    nan_df = pd.DataFrame(df.isna().sum()).reset_index()\n",
    "    nan_df.columns  = ['Column', 'NaN_Count']\n",
    "    nan_df['NaN_Count'] = nan_df['NaN_Count'].astype('int')\n",
    "    nan_df['NaN_%'] = round(nan_df['NaN_Count']/df.shape[0] * 100,4)\n",
    "    nan_df['Type']  = 'Missingness'\n",
    "    nan_df.sort_values('NaN_%', inplace=True)\n",
    "\n",
    "    # Add completeness\n",
    "    for i in range(nan_df.shape[0]):\n",
    "        complete_df = pd.DataFrame([nan_df.loc[i,'Column'],df.shape[0] - nan_df.loc[i,'NaN_Count'],100 - nan_df.loc[i,'NaN_%'], 'Completeness']).T\n",
    "        complete_df.columns  = ['Column','NaN_Count','NaN_%','Type']\n",
    "        complete_df['NaN_%'] = complete_df['NaN_%'].astype('int')\n",
    "        complete_df['NaN_Count'] = complete_df['NaN_Count'].astype('int')\n",
    "        nan_df = pd.concat([nan_df,complete_df], sort=True)\n",
    "            \n",
    "    nan_df = nan_df.rename(columns={\"Column\": \"Feature\", \"NaN_%\": \"Missing %\"})\n",
    "\n",
    "    # Missingness Plot\n",
    "    fig = px.bar(nan_df,\n",
    "                 x='Feature',\n",
    "                 y='Missing %',\n",
    "                 title=f\"Missingness Plot (N={df.shape[0]})\",\n",
    "                 color='Type',\n",
    "                 opacity = 0.6,\n",
    "                 color_discrete_sequence=['red','#808080'],\n",
    "                 width=800,\n",
    "                 height=800)\n",
    "    fig.show()\n",
    "\n",
    "plot_missingness(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8430d92",
   "metadata": {},
   "source": [
    "#### b) Remove columns and change type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8128ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that don't impact\n",
    "df = df.drop(['style','summary','image'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f7a34de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      59308\n",
       "3      29733\n",
       "4      17002\n",
       "5      10985\n",
       "6       7730\n",
       "       ...  \n",
       "266        1\n",
       "612        1\n",
       "247        1\n",
       "817        1\n",
       "414        1\n",
       "Name: vote, Length: 333, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vote'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5115353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert vote column to float\n",
    "\n",
    "df['vote']=df['vote'].str.replace(',','')\n",
    "df[\"vote\"]= df[\"vote\"].fillna(0)\n",
    "df[\"vote\"] = df[\"vote\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03f3ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert column to string\n",
    "df[\"reviewText\"]=df[\"reviewText\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a582fcf",
   "metadata": {},
   "source": [
    "#### c) Add Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0e209bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inserting helpful flag to be used in EDA and Models\n",
    "df['helpful_flag'] = np.where(df['vote'] > 0, 1, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "657a28c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average length of review: 208.585\n"
     ]
    }
   ],
   "source": [
    "#Determine Average Review Length and add review length column to dataframe\n",
    "\n",
    "x = [len(df['reviewText'][i]) for i in range(df['reviewText'].shape[0])]\n",
    "print('average length of review: {:.3f}'.format(sum(x)/len(x)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4870be67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Triston\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "#stop_words=['not', 'for','in','of', 'to']\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae4de0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to remove spaces from review so that we will only get characters.\n",
    "def char_counts(x):\n",
    "    s = x.split()\n",
    "    x = ''.join(s)\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a115fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding columns for NLP EDAS\n",
    "# df['totalWords'] = df['reviewText'].str.split().str.len()\n",
    "df['totalWords'] = df['reviewText'].apply( lambda x: len(str(x).split()))\n",
    "df['vocab_size'] = df['reviewText'].apply( lambda x: len(set(str(x).split())))\n",
    "df['char_counts'] = df['reviewText'].apply( lambda x: char_counts(str(x)))\n",
    "df['avg_word_size'] = df['char_counts']/df['totalWords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e9a6af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8404fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stopword_count'] = df['reviewText'].apply( lambda x: len([t for t in x.split() if t in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7765ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['numeric_count'] = df['reviewText'].apply( lambda x:len([t for t in x.split() if t.isdigit()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbd481d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UpperCase_word_count'] = df['reviewText'].apply( lambda x:len([t for t in x.split() if t.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fc63e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Capitalized_word_count'] = df['reviewText'].apply( lambda x:len([t for t in x.split() if t[0].isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b3b4fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Triston\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('because', 'IN'), ('he', 'PRP'), ('said', 'VBD')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "tags = nltk.pos_tag(\"because he said\".translate\n",
    "    (str.maketrans('', '', string.punctuation)).split())\n",
    "print(tags)\n",
    "noun_preceders = [a for (a, b) in tags if b in ('NN', 'NNS', 'NNP', 'NNPS') ]\n",
    "noun_preceders\n",
    "len(noun_preceders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bf6ba98",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     31\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'C:\\\\Users\\\\Triston/nltk_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mNouns_count\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mreviewText\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply( \u001b[39mlambda\u001b[39;49;00m x:\u001b[39mlen\u001b[39;49m([a \u001b[39mfor\u001b[39;49;00m (a, b) \u001b[39min\u001b[39;49;00m nltk\u001b[39m.\u001b[39;49mpos_tag(x\u001b[39m.\u001b[39;49mtranslate\n\u001b[0;32m      2\u001b[0m     (\u001b[39mstr\u001b[39;49m\u001b[39m.\u001b[39;49mmaketrans(\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, string\u001b[39m.\u001b[39;49mpunctuation))\u001b[39m.\u001b[39;49msplit()) \u001b[39mif\u001b[39;49;00m b \u001b[39min\u001b[39;49;00m (\u001b[39m'\u001b[39;49m\u001b[39mNN\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mNNS\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mNNP\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mNNPS\u001b[39;49m\u001b[39m'\u001b[39;49m) ]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mNouns_count\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mreviewText\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply( \u001b[39mlambda\u001b[39;00m x:\u001b[39mlen\u001b[39m([a \u001b[39mfor\u001b[39;00m (a, b) \u001b[39min\u001b[39;00m nltk\u001b[39m.\u001b[39;49mpos_tag(x\u001b[39m.\u001b[39;49mtranslate\n\u001b[0;32m      2\u001b[0m     (\u001b[39mstr\u001b[39;49m\u001b[39m.\u001b[39;49mmaketrans(\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, string\u001b[39m.\u001b[39;49mpunctuation))\u001b[39m.\u001b[39;49msplit()) \u001b[39mif\u001b[39;00m b \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mNN\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNNS\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNNP\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNNPS\u001b[39m\u001b[39m'\u001b[39m) ]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\tag\\__init__.py:165\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpos_tag\u001b[39m(tokens, tagset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, lang\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meng\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    141\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m    tag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     tagger \u001b[39m=\u001b[39m _get_tagger(lang)\n\u001b[0;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\tag\\__init__.py:107\u001b[0m, in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    105\u001b[0m     tagger\u001b[39m.\u001b[39mload(ap_russian_model_loc)\n\u001b[0;32m    106\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     tagger \u001b[39m=\u001b[39m PerceptronTagger()\n\u001b[0;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m tagger\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\tag\\perceptron.py:167\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m load:\n\u001b[0;32m    166\u001b[0m     AP_MODEL_LOC \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[1;32m--> 167\u001b[0m         find(\u001b[39m\"\u001b[39;49m\u001b[39mtaggers/averaged_perceptron_tagger/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m PICKLE)\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload(AP_MODEL_LOC)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\data.py:522\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[39m# Check each item in our path\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[39mfor\u001b[39;00m path_ \u001b[39min\u001b[39;00m paths:\n\u001b[0;32m    521\u001b[0m     \u001b[39m# Is the path item a zipfile?\u001b[39;00m\n\u001b[1;32m--> 522\u001b[0m     \u001b[39mif\u001b[39;00m path_ \u001b[39mand\u001b[39;00m (os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49misfile(path_) \u001b[39mand\u001b[39;00m path_\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m    523\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    524\u001b[0m             \u001b[39mreturn\u001b[39;00m ZipFilePathPointer(path_, resource_name)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Test whether a path is a regular file\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     31\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['Nouns_count'] = df['reviewText'].apply( lambda x:len([a for (a, b) in nltk.pos_tag(x.translate\n",
    "    (str.maketrans('', '', string.punctuation)).split()) if b in ('NN', 'NNS', 'NNP', 'NNPS') ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e8823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Verbs_count'] = df['reviewText'].apply( lambda x:len([a for (a, b) in nltk.pos_tag(x.translate\n",
    "    (str.maketrans('', '', string.punctuation)).split()) if b in ('VB', 'VBG', 'VBD', 'VBN', 'VBP', 'VBZ') ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Adj_count'] = df['reviewText'].apply( lambda x:len([a for (a, b) in nltk.pos_tag(x.translate\n",
    "    (str.maketrans('', '', string.punctuation)).split()) if b in ('JJ', 'JJR', 'JJS') ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Adverbs_count'] = df['reviewText'].apply( lambda x:len([a for (a, b) in nltk.pos_tag(x.translate\n",
    "    (str.maketrans('', '', string.punctuation)).split()) if b in ('RB', 'RBR', 'RBS') ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Conj_count'] = df['reviewText'].apply( lambda x:len([a for (a, b) in nltk.pos_tag(x.translate\n",
    "    (str.maketrans('', '', string.punctuation)).split()) if b in ('CC', 'IN', 'MD', 'RP') ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8dc896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create initial data set for first test \n",
    "df_initial = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aaa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataframe after add and changes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6797aa",
   "metadata": {},
   "source": [
    "#### d) Identify and discard duplicative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we looked to remove duplicates with the same review time and review IDs as they were assummed to be computer generated and not human generated \n",
    "\n",
    "\n",
    "duplicated_reviews = df.duplicated(subset=[\"reviewerID\",\"reviewTime\",\"reviewText\"], keep='first') #returns a Series with True and False values that describe which rows in the DataFrame are duplicated and not.\n",
    "count_duplicated_reviews = duplicated_reviews.value_counts()\n",
    "\n",
    "sum_reviews = count_duplicated_reviews.sum()\n",
    "perc_duplicated_reviews = (count_duplicated_reviews/sum_reviews) * 100\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"\",\"Count\",\"Percentage of Total\"]\n",
    "x.add_rows([\n",
    "    [\"Duplicate Reviews\", count_duplicated_reviews[True], perc_duplicated_reviews[True]],\n",
    "    [\"Original Reviews\", count_duplicated_reviews[False], perc_duplicated_reviews[False]],\n",
    "])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicates = df[duplicated_reviews]\n",
    "df_duplicates.sort_values(by = ['totalWords'], ascending = [False])\n",
    "df_duplicates[df_duplicates['vote'] == 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008cd368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[(df['reviewerID'] == 'A2N8B21NWXHIW7') & (df['unixReviewTime'] == 1469145600) ]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate reviews for df\n",
    "df = df[~duplicated_reviews]\n",
    "\n",
    "print(f\"Number of reviews after removel of duplicates : {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1da9e6",
   "metadata": {},
   "source": [
    "### EDA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bfcaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary Stats\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cfdb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation matrix for the \n",
    "sns.set(style=\"darkgrid\") # one of the many styles to plot using\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True) # one of the many color mappings\n",
    "f, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "sns.heatmap(df.corr(), cmap=cmap, annot=True)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58885fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create visual - duplicate code\n",
    "#selected_columns = ['overall','verified','vote', 'totalWords', 'helpful_flag']\n",
    "#df[selected_columns].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6415010",
   "metadata": {},
   "source": [
    "We can see that there is a weak to medium positive correlation between number of words and  helpful flag. \n",
    "There is weak positive correlation between votes and helpful flag even though the votes were used to create the helpful flag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a715a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create graph to check review distribution\n",
    "\n",
    "fig = px.histogram(df, x=\"overall\", color=\"overall\").update_xaxes(categoryorder='total descending')\n",
    "fig.update_xaxes(type='category')\n",
    "fig.update_layout(bargap=0.3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise: Added 11/27 DY\n",
    "labels = [f'{k} ({df[\"overall\"].value_counts()[k]} samples)' for k in df['overall'].value_counts().keys()]\n",
    "sizes = dict(df['overall'].value_counts()).values()\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(8,8))\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax1.set_title(\"Distribution of ratings in reviews\",pad=40, fontweight='bold', fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affdc05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-1, 0, 2, 5, 10, 25, 50, 100,3000]\n",
    "df['binned'] = pd.cut(df['vote'], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe23413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['binned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd5fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['helpful_flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial[df_initial['vote']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a5f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,7))\n",
    "\n",
    "ax = df['binned'].value_counts().plot(kind='bar')\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xlabel(\"Binned Votes\", labelpad=14)\n",
    "plt.ylabel(\"Count of Reviews\", labelpad=14)\n",
    "plt.title(\"Histogram for Votes (Binned)\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ddc48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,7))\n",
    "ax = df.loc[df['vote']>0,'overall'].value_counts().plot(kind='barh')\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xlabel(\"Number of Reviews\", labelpad=14)\n",
    "plt.ylabel(\"Number of Stars\", labelpad=14)\n",
    "plt.title(\"Helpful Reviews by Stars\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea817d9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Boxplot of Vote Counts by Score\n",
    "\n",
    "fig = px.box(df, x=\"vote\", color=\"overall\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create graph to check review distribution\n",
    "\n",
    "fig = px.histogram(df, x=\"helpful_flag\", color=\"overall\").update_xaxes(categoryorder='total descending')\n",
    "fig.update_xaxes(type='category')\n",
    "fig.update_layout(bargap=0.3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a9b74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072dcce1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Summary Stats\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check distribution of non zero votes\n",
    "\n",
    "df0 = df.loc[df['vote'] > 0]\n",
    "\n",
    "df0.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43bc48e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['helpful_flag'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da192a",
   "metadata": {},
   "source": [
    "We can see that the dataset is unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a25e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df[[ 'helpful_flag','overall']].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67780d",
   "metadata": {},
   "source": [
    "We noticed that the helpful is a much lower percentage than unhelpful but 5 star helpfuls was the largest type of helpful votes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8cd0f",
   "metadata": {},
   "source": [
    "### Create a balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137bb5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df['helpful_flag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce08c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "143572/969400  # only 14.8% records are helpful .. this data set is unbalanced .. we will create a balanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ce0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating helpful dataset\n",
    "df_helpful = df[df['helpful_flag']==1]\n",
    "df_helpful.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18541db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating nonhelpful dataset \n",
    "df_nothelpful = df[df['helpful_flag']==0]\n",
    "df_nothelpful.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d46a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsampling nonhelpful\n",
    "df_nothelpful_downsampled = df_nothelpful.sample(df_helpful.shape[0])\n",
    "df_nothelpful_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ee416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining for balanced data set\n",
    "\n",
    "df_nodups_balanced = pd.concat([df_nothelpful_downsampled, df_helpful])\n",
    "df_nodups_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b40ad6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df_initial['helpful_flag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d935e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d36f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "143572/969400  # only 14.8% records are helpful .. this data set is unbalanced .. we will create a balanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bafc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating helpful dataset\n",
    "df_helpful = df_initial[df_initial['helpful_flag']==1]\n",
    "df_helpful.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ff56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating nonhelpful dataset \n",
    "df_nothelpful = df_initial[df_initial['helpful_flag']==0]\n",
    "df_nothelpful.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsampling nonhelpful\n",
    "df_nothelpful_downsampled = df_nothelpful.sample(df_helpful.shape[0])\n",
    "df_nothelpful_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining for balanced data set\n",
    "\n",
    "df_balanced = pd.concat([df_nothelpful_downsampled, df_helpful])\n",
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2765573",
   "metadata": {},
   "source": [
    "### Creating random samples for NB and BERT Models\n",
    "\n",
    "We will create a sample for: \n",
    "- the initial df\n",
    "- the balanced df \n",
    "- the no_dups_balanced df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_sample = df_initial.sample(n = 20000, random_state = 1)\n",
    "df_balanced_sample = df_balanced.sample(n = 20000, random_state = 1)\n",
    "df_nodups_balanced_sample =df_nodups_balanced.sample(n = 20000, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa09dda",
   "metadata": {},
   "source": [
    "### initial Sample run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d013c651",
   "metadata": {},
   "source": [
    "#### NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Naive Bayes\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11637ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNB = df_initial_sample[['reviewText', 'helpful_flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Train-Test Split\n",
    "\n",
    "#https://towardsdatascience.com/how-to-split-a-dataset-into-training-and-testing-sets-b146b1649830\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, testing_data = train_test_split(dfNB, test_size=0.2, random_state=25)\n",
    "\n",
    "print(f\"No. of training examples: {training_data.shape[0]}\")\n",
    "print(f\"No. of testing examples: {testing_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_count = TfidfVectorizer()\n",
    "\n",
    "Xtrain = the_count.fit_transform(training_data['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73a154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.toarray()\n",
    "\n",
    "reverse = {j:i for i,j in the_count.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aed262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Multinomial Naive Bayes model for initial dataframe sample\n",
    "nb = MultinomialNB()\n",
    "nb.fit(Xtrain, training_data['helpful_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1853c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = the_count.transform(testing_data['reviewText'])\n",
    "preds = nb.predict(Xtest.toarray())\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0560fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_data['helpful_flag'],preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d81579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(testing_data['helpful_flag'],preds)\n",
    "\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d3030",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cnf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title(\"Confusion Matrix (Initial Dataset) NB Model\", y=1.02);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3652bd9",
   "metadata": {},
   "source": [
    "#### Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow for creating Bert Models\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd59c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder processing urls\n",
    "encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
    "preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the initial sample for BERT\n",
    "Bertdf = df_initial_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8716f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Bertdf['reviewText'],Bertdf['helpful_flag'], stratify=Bertdf['helpful_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a17701",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a13e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocessor = hub.KerasLayer(preprocess_url)\n",
    "bert_encoder = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e2988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_preprocessor(sentences)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f44ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocessor(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "intermediate_layer = tf.keras.layers.Dense(64, activation='relu', name='intermediate_layer')(l)\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(intermediate_layer)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "BERT_model = tf.keras.Model(inputs=[text_input], outputs = [output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533115c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b329ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-6)\n",
    "BERT_model.compile(optimizer=optim,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ccc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df8cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = BERT_model.predict(X_test)\n",
    "y_predicted = y_predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601654ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title(\"Confusion Matrix (Initial Dataset) BERT Model\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d845f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab4ceb",
   "metadata": {},
   "source": [
    "### Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c1d3b",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNB = df_balanced_sample[['reviewText', 'helpful_flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4223b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(dfNB, test_size=0.2, random_state=25)\n",
    "\n",
    "print(f\"No. of training examples: {training_data.shape[0]}\")\n",
    "print(f\"No. of testing examples: {testing_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0425d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_count = TfidfVectorizer()\n",
    "\n",
    "Xtrain = the_count.fit_transform(training_data['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b793a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.toarray()\n",
    "\n",
    "reverse = {j:i for i,j in the_count.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8aa421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Multinomial Naive Bayes model for initial dataframe sample\n",
    "nb = MultinomialNB()\n",
    "nb.fit(Xtrain, training_data['helpful_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b3f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = the_count.transform(testing_data['reviewText'])\n",
    "preds = nb.predict(Xtest.toarray())\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d0742",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_data['helpful_flag'],preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff16fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(testing_data['helpful_flag'],preds)\n",
    "\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c945b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cnf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title(\"Confusion Matrix (Balanced with Dups Dataset) NB Model\", y=1.02);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b230d3e",
   "metadata": {},
   "source": [
    "#### Bert Model  - Balanced (Dups) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3424262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder processing urls\n",
    "encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
    "preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the initial sample for BERT\n",
    "Bertdf = df_balanced_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Bertdf['reviewText'],Bertdf['helpful_flag'], stratify=Bertdf['helpful_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10607200",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocessor = hub.KerasLayer(preprocess_url)\n",
    "bert_encoder = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_preprocessor(sentences)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocessor(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "intermediate_layer = tf.keras.layers.Dense(64, activation='relu', name='intermediate_layer')(l)\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(intermediate_layer)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "BERT_model = tf.keras.Model(inputs=[text_input], outputs = [output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693dc78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b49856",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-6)\n",
    "BERT_model.compile(optimizer=optim,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020dcb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332036f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = BERT_model.predict(X_test)\n",
    "y_predicted = y_predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4332a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9982d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daed2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title(\"Confusion Matrix (Balanced Dups Dataset) BERT Model\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208eb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a64cf",
   "metadata": {},
   "source": [
    "###  Balanced no Dups Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9537b21",
   "metadata": {},
   "source": [
    "#### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNB = df_nodups_balanced_sample[['reviewText', 'helpful_flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fa0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(dfNB, test_size=0.2, random_state=25)\n",
    "\n",
    "print(f\"No. of training examples: {training_data.shape[0]}\")\n",
    "print(f\"No. of testing examples: {testing_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6538876",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_count = TfidfVectorizer()\n",
    "\n",
    "Xtrain = the_count.fit_transform(training_data['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d18ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.toarray()\n",
    "\n",
    "reverse = {j:i for i,j in the_count.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Multinomial Naive Bayes model for initial dataframe sample\n",
    "nb = MultinomialNB()\n",
    "nb.fit(Xtrain, training_data['helpful_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cd659",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = the_count.transform(testing_data['reviewText'])\n",
    "preds = nb.predict(Xtest.toarray())\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f417505",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_data['helpful_flag'],preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e58bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(testing_data['helpful_flag'],preds)\n",
    "\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f57c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cnf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title(\"Confusion Matrix (Balanced No Dups Dataset) NB Model\", y=1.02);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fbc734",
   "metadata": {},
   "source": [
    "#### Bert Model  - Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468826bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder processing urls\n",
    "encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
    "preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the initial sample for BERT\n",
    "Bertdf = df_nodups_balanced_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1998aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Bertdf['reviewText'],Bertdf['helpful_flag'], stratify=Bertdf['helpful_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0107226",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocessor = hub.KerasLayer(preprocess_url)\n",
    "bert_encoder = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae9955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_preprocessor(sentences)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1911d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocessor(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "intermediate_layer = tf.keras.layers.Dense(64, activation='relu', name='intermediate_layer')(l)\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(intermediate_layer)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "BERT_model = tf.keras.Model(inputs=[text_input], outputs = [output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4077080",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-6)\n",
    "BERT_model.compile(optimizer=optim,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = BERT_model.predict(X_test)\n",
    "y_predicted = y_predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d0f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dabd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f894f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title(\"Confusion Matrix (Balanced No Dups Dataset) BERT Model\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70c04d",
   "metadata": {},
   "source": [
    "Creating New EDA section for Lexical Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc39d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can see that the balanced data is getting the best scores.\n",
    "## we will now look at wordcount as it had high correlation to the helpful score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529863dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "sns.boxenplot(x=\"helpful_flag\", y=\"totalWords\",\n",
    "              color=\"b\", \n",
    "              scale=\"linear\", data=df[['totalWords','helpful_flag']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7f0d6",
   "metadata": {},
   "source": [
    "We can see that the more words in the review help in the getting a helpful vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef93ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create chart from excel in here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d47452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder processing urls\n",
    "the_count = TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdfa577",
   "metadata": {},
   "outputs": [],
   "source": [
    "### we are noticing that the low word counts are mostly unhelpful so we\n",
    "### are looking to convert the helpful flag to 0 for words under 10\n",
    "\n",
    "# create empty results df\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['wordcount', 'fl-score macro avg', 'fl-score helpful' , 'fl-score not helpful', 'fl-score accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Topics range\n",
    "min_word = 2\n",
    "max_word = 33\n",
    "step_size = 1\n",
    "word_range = range(min_word, max_word, step_size)\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(word_range)),  leave=True)\n",
    "    \n",
    "    # iterate through number of topics\n",
    "    for k in word_range:\n",
    "        df_nodups_balanced_sample['New_Helpful'] = np.where(df_nodups_balanced_sample['totalWords'] < k, 0, df_nodups_balanced_sample['helpful_flag'])\n",
    "        # using the initial sample for BERT\n",
    "        dfNB = df_nodups_balanced_sample[['reviewText', 'New_Helpful']]\n",
    "        training_data, testing_data = train_test_split(dfNB, test_size=0.2, random_state=25)\n",
    "        Xtrain = the_count.fit_transform(training_data['reviewText'])\n",
    "        Xtrain = Xtrain.toarray()\n",
    "        nb = MultinomialNB()\n",
    "        nb.fit(Xtrain, training_data['New_Helpful'])\n",
    "        Xtest = the_count.transform(testing_data['reviewText'])\n",
    "        preds = nb.predict(Xtest.toarray())\n",
    "        df_class_report = pd.DataFrame(classification_report(testing_data['New_Helpful'],preds, output_dict = True))\n",
    "        results_df = results_df.append({'wordcount' : k , 'fl-score macro avg' : df_class_report.loc['f1-score','macro avg'] , 'fl-score helpful' : df_class_report.loc['f1-score','1'], 'fl-score not helpful' : df_class_report.loc['f1-score','0'], 'fl-score accuracy' : df_class_report.loc['f1-score','accuracy']}, ignore_index=True)\n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "#    results_df['fl-score macro avg'] = df_class_report.loc['f1-score','macro avg']\n",
    "#    results_df['fl-score helpful'] = df_class_report.loc['f1-score','1']\n",
    "#    results_df['fl-score not helpful'] = df_class_report.loc['f1-score','0']\n",
    "#    results_df['fl-score accuracy'] = df_class_report.loc['f1-score','accuracy']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8120db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_report.loc['f1-score','macro avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623851bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5946696f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d8a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### we are noticing that the low word counts are mostly unhelpful so we\n",
    "### are looking to convert the helpful flag to 0 for words under 10\n",
    "\n",
    "# create empty results df\n",
    "\n",
    "results_top_df = pd.DataFrame(columns = ['wordcount', 'fl-score macro avg', 'fl-score helpful' , 'fl-score not helpful', 'fl-score accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Topics range\n",
    "min_word = 88\n",
    "max_word = 125\n",
    "step_size = 1\n",
    "word_range = range(min_word, max_word, step_size)\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(word_range)),  leave=True)\n",
    "    \n",
    "    # iterate through number of topics\n",
    "    for k in word_range:\n",
    "        df_nodups_balanced_sample['New_Helpful'] = np.where(df_nodups_balanced_sample['totalWords'] > k, 1, df_nodups_balanced_sample['helpful_flag'])\n",
    "        # using the initial sample for BERT\n",
    "        dfNB = df_nodups_balanced_sample[['reviewText', 'New_Helpful']]\n",
    "        training_data, testing_data = train_test_split(dfNB, test_size=0.2, random_state=25)\n",
    "        Xtrain = the_count.fit_transform(training_data['reviewText'])\n",
    "        Xtrain = Xtrain.toarray()\n",
    "        nb = MultinomialNB()\n",
    "        nb.fit(Xtrain, training_data['New_Helpful'])\n",
    "        Xtest = the_count.transform(testing_data['reviewText'])\n",
    "        preds = nb.predict(Xtest.toarray())\n",
    "        df_class_report = pd.DataFrame(classification_report(testing_data['New_Helpful'],preds, output_dict = True))\n",
    "        results_top_df = results_top_df.append({'wordcount' : k , 'fl-score macro avg' : df_class_report.loc['f1-score','macro avg'] , 'fl-score helpful' : df_class_report.loc['f1-score','1'], 'fl-score not helpful' : df_class_report.loc['f1-score','0'], 'fl-score accuracy' : df_class_report.loc['f1-score','accuracy']}, ignore_index=True)\n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "#    results_df['fl-score macro avg'] = df_class_report.loc['f1-score','macro avg']\n",
    "#    results_df['fl-score helpful'] = df_class_report.loc['f1-score','1']\n",
    "#    results_df['fl-score not helpful'] = df_class_report.loc['f1-score','0']\n",
    "#    results_df['fl-score accuracy'] = df_class_report.loc['f1-score','accuracy']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dfa2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_top_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfabd06",
   "metadata": {},
   "source": [
    " we see that if we limit the previous  that less than 25 words should be set to 0 and that more than 125 words should be set to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd27bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodups_balanced_sample['New_Helpful'] = np.where(df_nodups_balanced_sample['totalWords'] > 125, 1, df_nodups_balanced_sample['helpful_flag'])\n",
    "df_nodups_balanced_sample['New_Helpful'] = np.where(df_nodups_balanced_sample['totalWords'] < 25, 0, df_nodups_balanced_sample['New_Helpful'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb970837",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNB = df_nodups_balanced_sample[['reviewText', 'New_Helpful']]\n",
    "training_data, testing_data = train_test_split(dfNB, test_size=0.2, random_state=25)\n",
    "Xtrain = the_count.fit_transform(training_data['reviewText'])\n",
    "Xtrain = Xtrain.toarray()\n",
    "nb = MultinomialNB()\n",
    "nb.fit(Xtrain, training_data['New_Helpful'])\n",
    "Xtest = the_count.transform(testing_data['reviewText'])\n",
    "preds = nb.predict(Xtest.toarray())\n",
    "df_class_report = pd.DataFrame(classification_report(testing_data['New_Helpful'],preds, output_dict = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9655d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc89680",
   "metadata": {},
   "source": [
    "# Same data set using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder processing urls\n",
    "encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
    "preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63264d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the initial sample for BERT\n",
    "Bertdf = df_nodups_balanced_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Bertdf['reviewText'],Bertdf['New_Helpful'], stratify=Bertdf['New_Helpful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7f57c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f97c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocessor = hub.KerasLayer(preprocess_url)\n",
    "bert_encoder = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3cd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_preprocessor(sentences)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocessor(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "intermediate_layer = tf.keras.layers.Dense(64, activation='relu', name='intermediate_layer')(l)\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(intermediate_layer)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "BERT_model = tf.keras.Model(inputs=[text_input], outputs = [output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b958a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c48364",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-6)\n",
    "BERT_model.compile(optimizer=optim,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c38b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9acb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe617b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = BERT_model.predict(X_test)\n",
    "y_predicted = y_predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc5e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6536d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title(\"Confusion Matrix (New Helpful Column) BERT Model\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d433fae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132fd971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "abccc23d8b745288606dc03cd34dd9af4292ead0b0f04e93e928d4f842db1170"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
